## BGP 이용 네트워크 구성

### 개요

- Cilium이 BGP( Border Gateway Protocol ) 를 사용하여 연결된 라우터에 경로를 광고할 수 있는 방법을 제공
- BGP 피어, 정책 및 광고를 구성하는 유연한 방법을 제공하는 사용자 정의 리소스 세트로 관리


### 주요 구성요소

![alt text](./_image/BGP Diagram.png)

- CiliumBGPClusterConfig: 여러 노드에 적용되는 BGP 인스턴스와 피어 구성을 정의
- CiliumBGPPeerConfig: 공통적인 BGP 피어링 설정입니다. 여러 피어에서 사용
- CiliumBGPAdvertisement: BGP 라우팅 테이블에 삽입되는 접두사를 정의
- CiliumBGPNodeConfigOverride: 노드별 BGP 구성을 정의하여 더욱 세부적인 제어를 제공


### BGP Network 구성 실습

- 상단의 ToR Switch 역할을 해줄 VM(router)를 하나 추가 후 기본 라우팅 설정을 진행한다.
- 초기 설정한 클러스터와 다른 네트워크 대역을 만들고 워커 노드를 추가한다.
- Router VM에 frr 툴 설치 및 설정

  ```
  router bgp 65000
  bgp router-id 192.168.60.200
  bgp graceful-restart
  no bgp ebgp-requires-policy
  bgp bestpath as-path multipath-relax
  maximum-paths 4
  network 10.10.1.0/24
  neighbor CILIUM peer-group
  neighbor CILIUM remote-as external
  neighbor 192.168.60.100 peer-group CILIUM
  neighbor 192.168.60.101 peer-group CILIUM
  neighbor 192.168.160.100 peer-group CILIUM 
  ```

  ```bash
  systemctl daemon-reexec && systemctl restart frr
  systemctl status frr --no-pager --full
  ```

- BGP Node Label 설정

  ```bash
  kubectl label nodes cilium-control cilium-worker01 cilium-worker02 enable-bgp=true
  kubectl get node -l enable-bgp=true
  ```

- Cilium BPG 설정 (router 정보를 입력 후 어떤 IP 정보를 교환할 것인지 설정)

  ```yaml
  apiVersion: cilium.io/v2
  kind: CiliumBGPAdvertisement
  metadata:
    name: bgp-advertisements
    labels:
      advertise: bgp
  spec:
    advertisements:
      - advertisementType: "PodCIDR"
  ---
  apiVersion: cilium.io/v2
  kind: CiliumBGPPeerConfig
  metadata:
    name: cilium-peer
  spec:
    timers:
      holdTimeSeconds: 9
      keepAliveTimeSeconds: 3
    ebgpMultihop: 2
    gracefulRestart:
      enabled: true
      restartTimeSeconds: 15
    families:
      - afi: ipv4
        safi: unicast
        advertisements:
          matchLabels:
            advertise: "bgp"
  ---
  apiVersion: cilium.io/v2
  kind: CiliumBGPClusterConfig
  metadata:
    name: cilium-bgp
  spec:
    nodeSelector:
      matchLabels:
        "enable-bgp": "true"
    bgpInstances:
    - name: "instance-65001"
      localASN: 65001
      peers:
      - name: "tor-switch"
        peerASN: 65000
        peerAddress: 192.168.60.200  # router ip address
        peerConfigRef:
          name: "cilium-peer"
  ```

- Control Node에서 연결상태 확인

  ```bash
  ss -tnp | grep 179
  cilium bgp peers
  cilium bgp routes available ipv4 unicast
  kubectl get ciliumbgpadvertisements,ciliumbgppeerconfigs,ciliumbgpclusterconfigs
  kubectl get ciliumbgpnodeconfigs -o yaml | grep -A6 peeringState
  ```

- Router Node에서 연결 상태 확인

  ```bash
  ip -c route | grep bgp
  vtysh -c 'show ip bgp summary'
  vtysh -c 'show ip bgp'
  ```

- BGP로 학습한 라우팅 정보 확인

  ```bash
  # router node
  ip -c route | grep bgp
  172.20.0.0/24 nhid 96 via 192.168.60.100 dev eth1 proto bgp metric 20 
  172.20.1.0/24 nhid 94 via 192.168.60.101 dev eth1 proto bgp metric 20 
  172.20.2.0/24 nhid 92 via 192.168.160.100 dev eth2 proto bgp metric 20 
  ```

- TCPDUMP 정보 확인

  ```bash
  # control node
  tcpdump -i eth1 tcp port 179 -w /tmp/bgp.pcap
  # router node
  systemctl restart frr && journalctl -u frr -f
  # bgp.type == 2
  termshark -r bgp.pcap
  ```

- control node, worker01~02 node routing table 정보 추가

  ```bash
  # control node
  ip route add 172.20.0.0/16 via 192.168.60.200
  sshpass -p 'vagrant' ssh vagrant@cilium-worker01 sudo ip route add 172.20.0.0/16 via 192.168.60.200
  sshpass -p 'vagrant' ssh vagrant@cilium-worker02 sudo ip route add 172.20.0.0/16 via 192.168.160.200
  ```

  - 각 노드에서는 bgp update 정보를 받았지만 bgp가 직접 커널의 라우팅 정보를 수정하지 않기 때문에 수동으로 설정 필요

  - ToR Switch를 default gateway로 설정되어 있는 환경인 경우 이 과정은 불필요 (이미 router에서는 BGP로 경로 값이 학습되어 있기 때문)

  - 또는 default gateway가 tor 스위치로 향하지 않는 환경인 경우 수동으로 경로 설정이 필요함

- 정상 통신 확인

  ```bash
  kubectl exec -it curl-pod -- sh -c 'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'
  ```

### 참고

- 노드가 많은 대규모 클러스터의 경우, api 서버에 부하 유발할 수 있으니, bgp status reporting off 권장

  ```bash
  # CiliumBGPNodeConfig Status 정보 확인
  kubectl get ciliumbgpnodeconfigs -o yaml | yq
  # bgpControlPlane.statusReport.enabled=false 설정
  helm upgrade cilium cilium/cilium --version 1.18.0 --namespace kube-system --reuse-values \
  --set bgpControlPlane.statusReport.enabled=false
  kubectl -n kube-system rollout restart ds/cilium
  # CiliumBGPNodeConfig Status 정보 확인
  kubectl get ciliumbgpnodeconfigs -o yaml | yq
  ```

## LB IP BGP 광고

- LB IPAM 설정

  ```yaml
  apiVersion: "cilium.io/v2"
  kind: CiliumLoadBalancerIPPool
  metadata:
    name: "cilium-pool"
  spec:
    allowFirstLastIPs: "No"
    blocks:
    - cidr: "172.16.1.0/24"
  ```

  ```bash
  kubectl get ippool
  ```

- Cluster Type 서비스 LB Type 변경

  ```bash
  kubectl patch svc webpod -p '{"spec": {"type": "LoadBalancer"}}'
  kubectl get svc webpod 
  ```

  ```bash
  kubectl -n kube-system exec ds/cilium -c cilium-agent -- cilium-dbg service list | grep -A2 LoadBalancer
  16   172.16.1.1:80/TCP      LoadBalancer   1 => 172.20.1.20:80/TCP (active)        
                                            2 => 172.20.2.107:80/TCP (active)      
  ```

- BGP Announce 설정

 ```yaml
 apiVersion: cilium.io/v2
  kind: CiliumBGPAdvertisement
  metadata:
    name: bgp-advertisements-lb-exip-webpod
    labels:
      advertise: bgp
  spec:
    advertisements:
      - advertisementType: "Service"
        service:
          addresses:
            - LoadBalancerIP
        selector:             
          matchExpressions:
            - { key: app, operator: In, values: [ webpod ] }
  ```

  ```bash
  kubectl get CiliumBGPAdvertisement
  ```

  ```bash
  kubectl exec -it -n kube-system ds/cilium -- cilium-dbg bgp route-policies
  cilium bgp routes available ipv4 unicast
  ```

- router 에 추가된 라우팅 경로 확인

  ```bash
  sshpass -p 'vagrant' ssh vagrant@cilium-router ip -c route
  ...
  172.16.1.1 nhid 133 proto bgp metric 20 
        nexthop via 192.168.60.101 dev eth1 weight 1 
        nexthop via 192.168.60.100 dev eth1 weight 1 
        nexthop via 192.168.160.100 dev eth2 weight 1 
  ...
  ```

  ```bash
  sshpass -p 'vagrant' ssh vagrant@cilium-router "sudo vtysh -c 'show ip route bgp'"
  sshpass -p 'vagrant' ssh vagrant@cilium-router "sudo vtysh -c 'show ip bgp summary'"
  sshpass -p 'vagrant' ssh vagrant@cilium-router "sudo vtysh -c 'show ip bgp'"
  sshpass -p 'vagrant' ssh vagrant@cilium-router "sudo vtysh -c 'show ip bgp 172.16.1.1/32'"
  ```

- 통신 테스트 (control node)

  ```bash
  root@cilium-control:~# LBIP=$(kubectl get svc webpod -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
  root@cilium-control:~# curl -s $LBIP
  Hostname: webpod-697b545f57-7cnln
  IP: 127.0.0.1
  IP: ::1
  IP: 172.20.1.20
  IP: fe80::883d:f5ff:fe10:373e
  RemoteAddr: 192.168.60.100:35352
  GET / HTTP/1.1
  Host: 172.16.1.1
  User-Agent: curl/8.5.0
  Accept: */*

  root@cilium-control:~# curl -s $LBIP
  Hostname: webpod-697b545f57-9glcn
  IP: 127.0.0.1
  IP: ::1
  IP: 172.20.2.107
  IP: fe80::3455:45ff:fe8d:83bc
  RemoteAddr: 192.168.60.100:47042
  GET / HTTP/1.1
  Host: 172.16.1.1
  User-Agent: curl/8.5.0
  Accept: */*
  ```

- 통신 테스트 (router node)

  ```bash
  root@cilium-router:~# LBIP=172.16.1.1
  root@cilium-router:~# curl -s $LBIP
  Hostname: webpod-697b545f57-9glcn
  IP: 127.0.0.1
  IP: ::1
  IP: 172.20.2.107
  IP: fe80::3455:45ff:fe8d:83bc
  RemoteAddr: 192.168.60.100:45870
  GET / HTTP/1.1
  Host: 172.16.1.1
  User-Agent: curl/8.5.0
  Accept: */*

  root@cilium-router:~# curl -s $LBIP
  Hostname: webpod-697b545f57-7cnln
  IP: 127.0.0.1
  IP: ::1
  IP: 172.20.1.20
  IP: fe80::883d:f5ff:fe10:373e
  RemoteAddr: 192.168.60.100:45882  # control 노드에는 라우팅 대상이 없지만 계속 이곳으로 라우팅 되는 상태 
  GET / HTTP/1.1
  Host: 172.16.1.1
  User-Agent: curl/8.5.0
  Accept: */*
  ```

## Cilium ingress Support

- Cilium에서는 `ingressClassName`으로 `Cilium`을 사용하는 Ingress Controller를 제공한다.
- dedicated 모드는 ingress에 대한 전용 로드 밸런서를 생성한다.
- shared 모드는 모든 ingress가 공유할 로드 밸런서를 생성한다.
- Cilium에서 Ingress Controller를 사용하기 위해서는 `nodePort.enabled=true` 또는 `kubeProxyReplacement=true`를 사용해 kube-proxy를 대체 활성화 해야 한다.
- Cilium에서는 L7 Proxy(Envoy)를 통해서 구성된다.

### Cilium Ingress Controller, Gateway API와 기존의 Ingress Controller의 차이
- Cilium의 Ingress Controller, Gateway API는 다른 Ingress Controller와 다르게 CNI에서 제공하는 기술 스택의 일부로 구성되어 이전 Ingress Controller와는 다르게 동작한다.
- 다른 Ingress 또는 Gateway API 컨트롤러는 일반적으로 클러스터에 Deployment 또는 데몬셋으로 설치된다.
- Cilium Ingress 및 Gateway API 구성은 Loadbalancer 또는 NodePort 서비스를 통해 노출된다.
- 선택적으로 Host network에서도 노출될 수 있다.
- 트래픽이 서비스의 포트에 도착하면 eBPF 코드가 트래픽을 가로채어 Envoy에게 전달한다.
- 또한 Cilium의 네트워크 정책 엔진이 Ingress에서 들어오는 트래픽 경계와 트래픽에 CiliumNetworkPolicy를 적용할 수 있다.
- cilium ingress와 ingress nginx와 같은 별도의 controller를 병행 사용할 수 있다.

### 설정 

- lb 활성화

  ```bash
  helm upgrade cilium cilium/cilium --version 1.18.0 --namespace kube-system --reuse-values \
    --set ingressController.enabled=true \
    --set ingressController.loadbalancerMode=shared \
    --set loadBalancer.l7.backend=envoy
  ```

  ```bash
  kubectl -n kube-system rollout restart ds/cilium
  ```

  ```bash
  cilium config view | grep -E '^loadbalancer|l7'
  enable-l7-proxy                                   true
  loadbalancer-l7                                   envoy
  loadbalancer-l7-algorithm                         round_robin
  loadbalancer-l7-ports 
  ```

- lb ipam 설정

 ```bash
 cat << EOF | kubectl apply -f -
  apiVersion: "cilium.io/v2" 
  kind: CiliumLoadBalancerIPPool
  metadata:
    name: "cilium-lb-ippool"
  spec:
    blocks:
    - start: "192.168.10.211"
      stop:  "192.168.10.215"
  EOF
  ```

- L2 Accouncement 설정

  ```bash
  cat << EOF | kubectl apply -f -
  apiVersion: "cilium.io/v2alpha1"
  kind: CiliumL2AnnouncementPolicy
  metadata:
    name: policy1
  spec:
    interfaces:
    - eth1
    externalIPs: true
    loadBalancerIPs: true
  EOF
  ```

- 리더 인스턴스 조회

  ```bash
  $ kubectl -n kube-system get lease | grep "cilium-l2announce"
  cilium-l2announce-kube-system-cilium-ingress   cilium-w2
  ```

- LoadBalancer로 띄워진 cilium-ingress 정보 조회

  ```bash
  root@cilium-ctr:~# kubectl get svc -n kube-system cilium-ingress
  NAME             TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE
  cilium-ingress   LoadBalancer   10.96.149.41   192.168.10.211   80:32573/TCP,443:30748/TCP   3d13h
  root@cilium-ctr:~# kubectl get ingressclasses
  NAME     CONTROLLER                     PARAMETERS   AGE
  cilium   cilium.io/ingress-controller   <none>       3d13h
  ```

- ingress 생성 및 정보 조회

  ```bash
  # sample application
  root@cilium-ctr:~# kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.26/samples/bookinfo/platform/kube/bookinfo.yaml
  # sample ingress 
  root@cilium-ctr:~# cat << EOF | kubectl apply -f -
  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: basic-ingress
    namespace: default
  spec:
    ingressClassName: cilium
    rules:
    - http:
        paths:
        - backend:
            service:
              name: details
              port:
                number: 9080
          path: /details
          pathType: Prefix
        - backend:
            service:
              name: productpage
              port:
                number: 9080
          path: /
          pathType: Prefix
  EOF
  # ingress 정보 조회
  root@cilium-ctr:~# k get ing
  NAME            CLASS    HOSTS   ADDRESS          PORTS   AGE
  basic-ingress   cilium   *       192.168.10.211   80      4s
  ```

- ingress 통신 테스트

  ```bash
  LBIP=$(kubectl get svc -n kube-system cilium-ingress -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
  ```

  ```bash
  curl -so /dev/null -w "%{http_code}\n" http://$LBIP/
  curl -so /dev/null -w "%{http_code}\n" http://$LBIP/details/1
  ```

### ingress network policy 설정

- ingress와 관련된 모든 트래픽 차단

  ```bash
  cat << EOF | kubectl apply -f -
  apiVersion: "cilium.io/v2"
  kind: CiliumClusterwideNetworkPolicy
  metadata:
    name: "external-lockdown"
  spec:
    description: "Block all the traffic originating from outside of the cluster"
    endpointSelector: {}
    ingress:
    - fromEntities:
      - cluster
  EOF
  ```

  ```bash
  root@cilium-ctr:~# kubectl get ciliumclusterwidenetworkpolicy
  NAME                VALID
  external-lockdown   True
  ```

  ```bash
  root@cilium-ctr:~# curl --fail -v http://"$LBIP"/details/1
  *   Trying 192.168.10.211:80...
  * Connected to 192.168.10.211 (192.168.10.211) port 80
  > GET /details/1 HTTP/1.1
  > Host: 192.168.10.211
  > User-Agent: curl/8.5.0
  > Accept: */*
  > 
  < HTTP/1.1 403 Forbidden
  < content-length: 15
  < content-type: text/plain
  < date: Fri, 22 Aug 2025 05:44:03 GMT
  < server: envoy
  * The requested URL returned error: 403
  * Closing connection
  curl: (22) The requested URL returned error: 403
  ```

- hubble 관측 결과 확인

  ```bash
  root@cilium-ctr:~# cilium hubble port-forward&
  root@cilium-ctr:~# hubble observe -f --identity ingress
  ```

  ```bash
  root@cilium-ctr:~# curl --fail -v http://"$LBIP"/details/1
  Aug 22 05:46:14.512: 127.0.0.1:47282 (ingress) -> 127.0.0.1:13618 (world) http-request DROPPED (HTTP/1.1 GET http://192.168.10.211/details/1)
  Aug 22 05:46:14.512: 127.0.0.1:47282 (ingress) <- 127.0.0.1:13618 (world) http-response FORWARDED (HTTP/1.1 403 0ms (GET http://192.168.10.211/details/1))
  ```

  ```bash
  root@cilium-ctr:~# sshpass -p 'vagrant' ssh vagrant@cilium-r curl -s http://$LBIP/details/1 -v
  Aug 22 05:46:43.680: 192.168.10.200:35288 (ingress) -> 192.168.10.211:80 (world) http-request DROPPED (HTTP/1.1 GET http://192.168.10.211/details/1)
  Aug 22 05:46:43.680: 192.168.10.200:35288 (ingress) <- 192.168.10.211:80 (world) http-response FORWARDED (HTTP/1.1 403 0ms (GET http://192.168.10.211/details/1))
  ```

- 허용 정책 추가

  ```bash
  cat << EOF | kubectl apply -f -
  apiVersion: "cilium.io/v2"
  kind: CiliumClusterwideNetworkPolicy
  metadata:
    name: "allow-cidr"
  spec:
    description: "Allow all the traffic originating from a specific CIDR"
    endpointSelector:
      matchExpressions:
      - key: reserved:ingress
        operator: Exists
    ingress:
    - fromCIDRSet:
      # Please update the CIDR to match your environment
      - cidr: 192.168.10.200/32
      - cidr: 127.0.0.1/32
  EOF
  ```

  ```bash
  root@cilium-ctr:~# kubectl get ciliumclusterwidenetworkpolicy
  NAME                VALID
  allow-cidr          True
  external-lockdown   True
  ```

- 통신 테스트 추가

  ```bash
  root@cilium-ctr:~# curl --fail -v http://"$LBIP"/details/1
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) policy-verdict:L3-Only INGRESS ALLOWED (TCP Flags: SYN)
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: SYN)
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) to-network FORWARDED (TCP Flags: SYN, ACK)
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: ACK)
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
  Aug 22 05:48:31.222: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:48:31.223: 172.20.0.214:46089 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) to-network FORWARDED (TCP Flags: ACK, PSH)
  Aug 22 05:48:31.279: 127.0.0.1:49514 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) http-request FORWARDED (HTTP/1.1 GET http://192.168.10.211/details/1)
  Aug 22 05:48:31.280: 127.0.0.1:49514 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) http-response FORWARDED (HTTP/1.1 200 1ms (GET http://192.168.10.211/details/1))
  ```

  ```bash
  root@cilium-ctr:~# sshpass -p 'vagrant' ssh vagrant@cilium-r curl -s http://$LBIP/details/1 -v
  Aug 22 05:49:01.258: 172.20.0.214:46089 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) to-network FORWARDED (TCP Flags: ACK, FIN)
  Aug 22 05:49:01.259: 172.20.0.214:46089 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: ACK, FIN)
  Aug 22 05:49:02.890: 172.20.2.187:33589 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) policy-verdict:L3-Only INGRESS ALLOWED (TCP Flags: SYN)
  Aug 22 05:49:02.890: 172.20.2.187:33589 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: SYN)
  Aug 22 05:49:02.890: 172.20.2.187:33589 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) to-network FORWARDED (TCP Flags: SYN, ACK)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: ACK)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.891: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.892: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.892: 172.20.2.187:33589 (ingress) <> default/details-v1-766844796b-vldmp (ID:22766) pre-xlate-rev TRACED (TCP)
  Aug 22 05:49:02.892: 172.20.2.187:33589 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) to-network FORWARDED (TCP Flags: ACK, PSH)
  Aug 22 05:49:02.948: 192.168.10.200:46248 (ingress) -> default/details-v1-766844796b-vldmp:9080 (ID:22766) http-request FORWARDED (HTTP/1.1 GET http://192.168.10.211/details/1)
  Aug 22 05:49:02.950: 192.168.10.200:46248 (ingress) <- default/details-v1-766844796b-vldmp:9080 (ID:22766) http-response FORWARDED (HTTP/1.1 200 2ms (GET http://192.168.10.211/details/1))
  ```

- 정책 삭제

  ```bash
  root@cilium-ctr:~# kubectl delete CiliumClusterwideNetworkPolicy --all
  root@cilium-ctr:~# kubectl get ciliumclusterwidenetworkpolicy
  No resources found
  ```

### Dedicated Mode 생성

  ```bash
  cat << EOF | kubectl apply -f -
  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: webpod-ingress
    namespace: default
    annotations:
      ingress.cilium.io/loadbalancer-mode: dedicated
  spec:
    ingressClassName: cilium
    rules:
    - http:
        paths:
        - backend:
            service:
              name: webpod
              port:
                number: 80
          path: /
          pathType: Prefix
  EOF
  ```

- 생성 결과 확인 (shared ingress와 external ip가 다름)

  ```bash
  root@cilium-ctr:~# k get ing
  NAME             CLASS    HOSTS   ADDRESS          PORTS   AGE
  basic-ingress    cilium   *       192.168.10.211   80      68m
  webpod-ingress   cilium   *       192.168.10.212   80      3s
  ```

  ```bash
  root@cilium-ctr:~# k get svc -A | grep cilium-ingress
  default             cilium-ingress-webpod-ingress   LoadBalancer   10.96.255.186   192.168.10.212   80:32121/TCP,443:32296/TCP   3m14s
  kube-system         cilium-ingress                  LoadBalancer   10.96.149.41    192.168.10.211   80:32573/TCP,443:30748/TCP   3d14h- 통신 테스트
  root@cilium-ctr:~# k get ep -A | grep cilium-ingress
  Warning: v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
  default             cilium-ingress-webpod-ingress   192.192.192.192:9999                                                      3m48s
  kube-system         cilium-ingress                  192.192.192.192:9999                                                      3d14h
  ```

- dedicated ingress의 리더 노드 확인

  ```bash
  root@cilium-ctr:~# kubectl get lease -n kube-system | grep ingress
  cilium-l2announce-default-cilium-ingress-webpod-ingress   cilium-w1                                                                   4m11s
  cilium-l2announce-kube-system-cilium-ingress              cilium-w2                                                                   103m
  ```

- 통신 테스트

  ```bash
  root@cilium-ctr:~# sshpass -p 'vagrant' ssh vagrant@cilium-r curl -s http://$LB2IP
  Hostname: webpod-697b545f57-zc48g
  IP: 127.0.0.1
  IP: ::1
  IP: 172.20.1.172
  IP: fe80::aa:49ff:fefb:1f50
  RemoteAddr: 10.0.2.15:38034
  GET / HTTP/1.1
  Host: 192.168.10.212
  User-Agent: curl/8.5.0
  Accept: */*
  X-Envoy-Internal: true
  X-Forwarded-For: 192.168.10.200
  X-Forwarded-Proto: http
  X-Request-Id: aef276be-a1eb-48a6-8971-ca85510b15dc
  ```

  ```bash
  Aug 22 05:56:35.146: 10.0.2.15:38034 (ingress) -> default/webpod-697b545f57-zc48g:80 (ID:46081) to-endpoint FORWARDED (TCP Flags: SYN)
  Aug 22 05:56:35.146: 10.0.2.15:38034 (ingress) -> default/webpod-697b545f57-zc48g:80 (ID:46081) to-endpoint FORWARDED (TCP Flags: ACK)
  Aug 22 05:56:35.146: 192.168.10.200:48684 (ingress) -> default/webpod-697b545f57-zc48g:80 (ID:46081) http-request FORWARDED (HTTP/1.1 GET http://192.168.10.212/)
  Aug 22 05:56:35.146: 10.0.2.15:38034 (ingress) -> default/webpod-697b545f57-zc48g:80 (ID:46081) to-endpoint FORWARDED (TCP Flags: ACK, PSH)
  Aug 22 05:56:35.146: 192.168.10.200:48684 (ingress) <- default/webpod-697b545f57-zc48g:80 (ID:46081) http-response FORWARDED (HTTP/1.1 200 1ms (GET http://192.168.10.212/))
  Aug 22 05:56:38.607: 10.0.2.15:35482 (ingress) -> default/webpod-697b545f57-g2gpc:80 (ID:46081) to-endpoint FORWARDED (TCP Flags: ACK)
  ```